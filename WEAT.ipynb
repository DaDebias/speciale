{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import  packages\n",
    "import numpy as np\n",
    "import gensim\n",
    "import danlp\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First all functions that are needed to do the Word Embedding Association Test (WEAT) are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2, embedding):\n",
    "    \"\"\"\n",
    "    Returns cosine of the angle between two vectors\n",
    "    The function first loads the embeddings for the two words v1 and v2 that the cosine similarity has to be calculated for. \n",
    "    It then calculates the cosine similarity using the formula: cos(x, y) = x . y / |x| * |y|\n",
    "    np.dot returns the dot product of the vectors x and y (x . y)\n",
    "    np.linalg.norm returns the length of the given vector (|x| and |y|)\n",
    "    \n",
    "    \"\"\"\n",
    "    v1 = embedding[v1]\n",
    "    v2 = embedding[v2]\n",
    "    cos = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_association(W, A, B, embedding):\n",
    "    \"\"\"\n",
    "    The function makes two lists - one that stores the cosine distance between a target word W and all of attribute words in A and one storing the cosine distance between the target word W and all attribute words in B.\n",
    "    Cosine distance is calculated by the function defined as cosine_sim \n",
    "    The function returns the difference in means between the word W's association with the attributes A and B\n",
    "    Returns what corresponds to s(w, A, B) in the equations defined in the thesis\n",
    "\n",
    "    \"\"\"\n",
    "    cosine_scoresA = [] #create an empty list for associations between W and words in A\n",
    "    cosine_scoresB = [] #create an empty list for associations between W and words in B\n",
    "    for i in A:\n",
    "        cosine_scoresA.append(cosine_sim(W, i, embedding))\n",
    "    for i in B:\n",
    "        cosine_scoresB.append(cosine_sim(W, i, embedding))\n",
    "        \n",
    "    association = np.mean(cosine_scoresA) - np.mean(cosine_scoresB)\n",
    "    \n",
    "    return association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_differential_association(X, Y, A, B, embedding):\n",
    "    \"\"\"\n",
    "    The function calculates the differential association\n",
    "    It uses the function defined above (weat_association) to calculate the different in association between a given \n",
    "    word W's association with words in respectively A and B - but it iterates for all words W in respectively X and Y\n",
    "    Returns what corresponds to s(X, Y, A, B) in the equations\n",
    "    \"\"\"\n",
    "    associationX = []\n",
    "    associationY = []\n",
    "    for i in X:\n",
    "        associationX.append(weat_association(i, A, B, embedding))\n",
    "    for i in Y:\n",
    "        associationY.append(weat_association(i, A, B, embedding))\n",
    "    \n",
    "    diff_association = np.sum(associationX) - np.sum(associationY)\n",
    "    \n",
    "    return diff_association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_effect_size(X, Y, A, B,embedding):\n",
    "    \"\"\"\n",
    "    Calculates the WEAT effect size as described in the thesis\n",
    "    \"\"\"\n",
    "      \n",
    "    associationX = []\n",
    "    associationY = []\n",
    "    for i in X:\n",
    "        associationX.append(weat_association(i, A, B, embedding))\n",
    "    for i in Y:\n",
    "        associationY.append(weat_association(i, A, B, embedding))\n",
    "    associationXY = []\n",
    "    associationXY = associationX + associationY\n",
    "    tmp1 = np.mean(associationX) - np.mean(associationY)\n",
    "    tmp2 = np.std(associationXY,ddof=1) \n",
    "        \n",
    "    effect_size = tmp1/tmp2\n",
    "    \n",
    "    return effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permutation test p-value - has to be adjusted + code has to run more smoothly\n",
    "def weat_p_value(X, Y, A, B, embedding, p):\n",
    "    \"\"\"\n",
    "    Returns one-sided p-value of the permutation test \n",
    "    What the permutation test basically does: makes a lot (i) possible combinations of our target words and assesses\n",
    "    their association to the attributes. The proportion of differential association that are higher for permuted distributions \n",
    "    than for the non permuted distrubition are then calculated, which is the permutation test p-value\n",
    "\n",
    "    \"\"\"\n",
    "    diff_association = weat_differential_association(X, Y, A, B, embedding)\n",
    "    target_words = np.concatenate((X, Y), axis=0)\n",
    "    np.random.shuffle(target_words) #shuffle target words before permutations\n",
    "    \n",
    "    #Test if target words can be divided into two sets of equal size - otherwise print warning\n",
    "    if target_words.shape[0] % 2 != 0:\n",
    "        print('WARNING - target word set can not be divided into two sets of equal size')\n",
    "        \n",
    "    partition_diff_association = [] #Create empty list to be filled during loop\n",
    "\n",
    "    for i in range(p): #Iterate p times (number of permutations)\n",
    "        seq = np.random.permutation(target_words) #Permute target words\n",
    "        partition_X = seq[:len(seq)//2] #Load  first partition of data to create to sets of permuted target words\n",
    "        partition_Y = seq[len(seq)//2:] #Load second partition of data to create to sets of permuted target words\n",
    "        #Calculate and append differential association for permuted target words to attributes\n",
    "        partition_diff_association.append(weat_differential_association(partition_X, partition_Y, A, B, embedding))\n",
    "      \n",
    "    partition_diff_association = np.array(partition_diff_association) #Convert differential association for all permuted samples to numpy array\n",
    "\n",
    "    mean = np.mean(partition_diff_association) #Mean differential association for permutations\n",
    "    stdev = np.std(partition_diff_association) #Standard deviation of differential association for permutations\n",
    "    pvalue = ((np.sum(partition_diff_association > diff_association)+1) / (len(partition_diff_association)+1)) #Calculation of p-value, corresponds to proportion of differential association for permuted target words that are higher than for the non permuted value\n",
    "    \n",
    "    return diff_association, mean, stdev, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next section runs the results for each model individually, as it is too computationally expensive to run all models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we make one function that returns all relevant values for one embedding and one kind of gender bias\n",
    "\n",
    "def results_weat(X, Y, A, B, embedding, p):\n",
    "    #Define empty lists\n",
    "    diff_association = []\n",
    "    effect_size = []\n",
    "    pvalue = []\n",
    "\n",
    "    #Retrieve values from already defined functions\n",
    "    diff_association = weat_differential_association(X, Y, A, B, embedding)\n",
    "    effect_size = weat_effect_size(X, Y, A, B,embedding)\n",
    "    pvalue = weat_p_value(X, Y, A, B, embedding, p)[3]\n",
    "    \n",
    "    #Combine all values in dataframe\n",
    "    s1=pd.Series(diff_association,name='diff_association')\n",
    "    s2=pd.Series(effect_size,name='effect_size')\n",
    "    s3=pd.Series(pvalue ,name='pvalue')\n",
    "\n",
    "    results = pd.concat([s1,s2,s3], axis=1)\n",
    "        \n",
    "    #Return dataframe with all results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now run the tests for all types of gender biases (science vs. arts, math vs. arts, career vs. family) + all pre-trained models (separately as computational strain is too big otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.models.embeddings  import load_wv_with_gensim\n",
    "\n",
    "embeddings1 = load_wv_with_gensim('wiki.da.wv') #fastText Facebook wiki\n",
    "\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target a and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.models.embeddings  import load_wv_with_gensim\n",
    "\n",
    "embeddings2 = load_wv_with_gensim('cc.da.wv') #fastText Facebook wiki + CommonCrawl\n",
    "\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.models.embeddings  import load_wv_with_gensim\n",
    "\n",
    "embeddings3 = load_wv_with_gensim('conll17.da.wv') #word2vec Skipgram CoNLL2017\n",
    "\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings3, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings3, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings3, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "embeddings4 = gensim.models.fasttext.load_facebook_vectors('datenten14_5.bin')  \n",
    "\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings4, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings4, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings4, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.models.embeddings  import load_wv_with_gensim, load_wv_with_spacy\n",
    "\n",
    "embeddings5 = load_wv_with_gensim('dslreddit.da.wv') #word2vec CBOW DSL Reddit\n",
    "\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings5, p)"
   ]
  },
  {
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "#embeddings6 = KeyedVectors.load_word2vec_format('danish_newspapers_1880To2013.txt', binary=False) \n",
    "\n",
    "model_test = KeyedVectors.load_word2vec_format('/work/dagw_wordembeddings/fasttext_model/fasttext_vectors.txt')\n",
    "import os\n",
    "print(os.getcwd())\n",
    "#Set permutations\n",
    "p =10000\n",
    "\n",
    "#Set target and attribute words - Science vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['videnskab', 'teknologi', 'fysik', 'kemi', 'rumfart', 'eksperiment', 'astronomi', 'biologi'] #Target words for Science\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur', 'roman', 'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "#results_weat(X, Y, A, B, model_test, p)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 0 to array axis with dimension 300",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a8be20ec9897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#embeddings6 = KeyedVectors.load_word2vec_format('danish_newspapers_1880To2013.txt', binary=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/work/dagw_wordembeddings/fasttext_model/fasttext_vectors.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1629\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         )\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             )\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1882\u001b[0;31m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_add_word_to_kv\u001b[0;34m(kv, counts, word, weights, vocab_size)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"duplicate word '%s' in word2vec file, ignoring all but first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m     \u001b[0mword_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36madd_vector\u001b[0;34m(self, key, vector)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 0 to array axis with dimension 300"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Math vs. Arts\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['matematik', 'algebra', 'geometri', 'regning', 'ligninger', 'beregning', 'tal', 'addition'] #Target words for Math\n",
    "Y = ['poesi', 'kunst', 'dans', 'litteratur',  'roman' ,'symfoni', 'drama', 'skulptur'] #Target words for Arts\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings6, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and attribute words - Career vs. Family\n",
    "A = ['mandlig', 'mand','dreng','bror','han','ham','hans','søn'] #Attribute words for mand\n",
    "B = ['kvindelig', 'kvinde', 'pige', 'søster', 'hun', 'hende', 'hendes', 'datter'] #Attribute words for kvinde\n",
    "X = ['leder', 'ledelse', 'professionel', 'virksomhed', 'løn', 'kontor', 'forretning', 'karriere'] #Target words for Career\n",
    "Y = ['hjem','forældre', 'børn', 'familie','bedsteforældre', 'ægteskab', 'bryllup', 'pårørende'] #Target words for Family\n",
    "\n",
    "results_weat(X, Y, A, B, embeddings6, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}